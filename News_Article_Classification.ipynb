{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87c2bef6-a54a-45a0-8a91-eb64cfd9fd2d",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING MODEL FOR NEWS ARTICLE CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7296a5-7047-4dcb-a208-7b68d7e24661",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "83b0fac8-a722-4296-99f6-6f286f67eca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab649381-4a05-4725-958c-4b89cf16f505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy 1.26.4\n",
      "pandas 2.2.2\n",
      "sklearn 1.4.2\n"
     ]
    }
   ],
   "source": [
    "print(\"numpy\",np.__version__)\n",
    "print(\"pandas\",pd.__version__)\n",
    "print(\"sklearn\",sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "336fbb17-c071-4285-965a-74acabc2b4c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>TITLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>A closer look at water-splitting's solar fuel ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>An irresistible scent makes locusts swarm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>Artificial intelligence warning: AI will know ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>Glaciers Could Have Sculpted Mars Valleys: Study</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>Perseid meteor shower 2020: What time and how ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CATEGORY                                              TITLE\n",
       "0  SCIENCE  A closer look at water-splitting's solar fuel ...\n",
       "1  SCIENCE          An irresistible scent makes locusts swarm\n",
       "2  SCIENCE  Artificial intelligence warning: AI will know ...\n",
       "3  SCIENCE   Glaciers Could Have Sculpted Mars Valleys: Study\n",
       "4  SCIENCE  Perseid meteor shower 2020: What time and how ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating pandas DataFrame\n",
    "df = pd.read_csv('NEWS_CATEGORY_DATASET.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75b031b2-fbf3-4258-9b1d-f8e5ca5eeb64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SCIENCE', 'TECHNOLOGY', 'HEALTH', 'WORLD', 'ENTERTAINMENT',\n",
       "       'SPORTS', 'BUSINESS', 'NATION'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# News Categories\n",
    "pd.unique(df['CATEGORY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3661acd-24c5-4501-b221-0ff678ab3bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 108691 entries, 0 to 108690\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   CATEGORY  108691 non-null  object\n",
      " 1   TITLE     108627 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.7+ MB\n",
      "Index(['CATEGORY', 'TITLE'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cfa334-520c-4a30-af13-9deaae58b4d2",
   "metadata": {},
   "source": [
    "### Tokenizing Titles\n",
    "\n",
    "It helps in breaking text into individual components (tokens), simplifying processing and allowing models to map words to numerical representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59ee3c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/mdshahbazshamim/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4801ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libreary\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "TOKENIZED_TITLES = []\n",
    "\n",
    "for headline in df['TITLE']:\n",
    "    if isinstance(headline, str):  # Check if the value is a string\n",
    "        TOKENIZED_TITLES.append(word_tokenize(headline.lower()))\n",
    "    else:\n",
    "        TOKENIZED_TITLES.append([])  # Handle non-string values, you can modify this as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3263cc2e-72fc-4e59-8daa-e7c59e9d1521",
   "metadata": {},
   "source": [
    "### Pickling Tokenized Titles\n",
    "\n",
    "It conserves time by retaining the processed data for future use, which removes the necessity of re-tokenizing with each model run. This approach guarantees consistency, accelerates workflows, and facilitates the sharing of preprocessed data between teams, resulting in more effective and organized projectÂ execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78cc1990-41d8-44eb-9980-1bb9d10b1712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required library\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Ensureing the directory exists\n",
    "os.makedirs('pklFiles', exist_ok=True)\n",
    "\n",
    "# Now open the file and pickle data\n",
    "file = \"pklFiles/TOKENIZED_TITLES.pkl\"\n",
    "with open(file, 'wb') as fileobj:\n",
    "    pickle.dump(TOKENIZED_TITLES, fileobj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e67f62a-edb6-4339-8442-89e96f475211",
   "metadata": {},
   "source": [
    "### Removal of stop words , punctuation & Possessives ('s)\n",
    "\n",
    "Eliminating stop words, punctuation, and possessives aids in refining the data by eliminating unnecessary details. enables the model to concentrate on the key terms, thereby enhancing its precision and effectiveness. Additionally, it simplifies the text, making it easier for the model to comprehend and process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3f33a094-4709-4494-88aa-159fabc7130c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop words : \n",
      "{'which', 'few', 'than', 'hadn', \"doesn't\", 'do', 't', 'under', 'an', \"don't\", \"should've\", 'himself', 'until', \"he'd\", \"she'd\", \"we'd\", 'both', \"they'd\", \"it'd\", \"mustn't\", \"they'll\", 'don', 's', 'below', 'myself', \"she'll\", \"won't\", 'herself', 'can', 'all', \"isn't\", 'ma', 'because', 'our', 'being', 'll', 'where', 'just', 'when', 'your', \"hadn't\", 'am', 'their', 'once', 'she', 'doing', 'couldn', 'i', 'through', 'aren', 'in', 'won', 'further', \"hasn't\", 'of', 'up', 'those', 'haven', 'needn', 'me', 'as', 'above', 'how', 'more', 'before', \"mightn't\", 'against', 'he', 'between', 'shouldn', 'very', 'any', 'been', \"you'd\", 'over', 'so', 'each', 'itself', 'who', 'y', 'a', 'her', 'should', 'nor', 'most', 'doesn', 'about', 'some', \"aren't\", 'didn', 'for', 'm', 'had', \"it's\", 'will', 'mustn', 'own', \"they're\", 'isn', \"i've\", 'o', 'same', 'why', \"they've\", \"weren't\", 'them', 'down', 'be', 'from', 'that', 'there', 'themselves', \"i'm\", \"shan't\", 'after', 'into', \"needn't\", 'no', 'out', 'too', 'its', \"he'll\", 'or', 'what', \"shouldn't\", 'now', 'does', \"i'll\", 'wouldn', \"it'll\", \"he's\", 'wasn', 'shan', 'did', 'has', 'are', 'theirs', 'off', 'at', 'hasn', 'have', 'other', 'only', 'mightn', 'if', 'weren', 're', \"couldn't\", 'him', 'it', 'yourselves', 'his', \"haven't\", \"we're\", 'these', \"she's\", 'and', \"wouldn't\", 'while', 'by', 'such', 'yours', 'they', 'during', 've', 'you', 'having', 'yourself', \"that'll\", \"you'll\", 'my', 'again', 'here', 'but', \"didn't\", 'on', \"i'd\", 'ours', 'hers', 'not', 'with', 'is', \"you've\", 'was', 'whom', \"you're\", 'to', 'ain', 'the', 'then', 'ourselves', 'we', \"we'll\", 'were', \"wasn't\", \"we've\", 'this', 'd'}\n",
      "\n",
      "punctuations : \n",
      "{'(', '$', '}', '*', '>', ',', '/', '%', ']', '#', '`', ')', '\"', '{', '=', '.', ';', '@', '!', '[', '+', '_', '?', '&', '|', '-', \"'\", ':', '\\\\', '~', '<', '^'}\n",
      "\n",
      "Filtered Titles : \n",
      "[['closer', 'look', 'water-splitting', 'solar', 'fuel', 'potential'], ['irresistible', 'scent', 'makes', 'locusts', 'swarm'], ['artificial', 'intelligence', 'warning', 'ai', 'know', 'us', 'better', 'know'], ['glaciers', 'could', 'sculpted', 'mars', 'valleys', 'study'], ['perseid', 'meteor', 'shower', '2020', 'time', 'see', 'huge', 'bright', 'fireballs', 'uk', 'tonight']]\n"
     ]
    }
   ],
   "source": [
    "# Required Libraries\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "# stop words for English language\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "print(\"stop words : \")\n",
    "print(stop_words)\n",
    "\n",
    "# punctuations\n",
    "punctuations = set(string.punctuation)\n",
    "print(\"\\npunctuations : \")\n",
    "print(punctuations)\n",
    "\n",
    "# FILTERED TITLE = Title without stop words & punctuations\n",
    "FILTERED_TITLES = []\n",
    "\n",
    "for title in TOKENIZED_TITLES:\n",
    "    temp_title = []\n",
    "    for word in title:\n",
    "        if((word not in stop_words) and (word not in punctuations) and (word != \"'s\")):\n",
    "            temp_title.append(word)\n",
    "\n",
    "    FILTERED_TITLES.append(temp_title)\n",
    "\n",
    "print(\"\\nFiltered Titles : \")\n",
    "print(FILTERED_TITLES[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d5e42a73-b4f9-4d8a-a4f8-91172c05a741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling FILTERED_TITLES\n",
    "\n",
    "file = \"pklFiles/FILTERED_TITLES.pkl\"\n",
    "with open(file, 'wb') as fileobj:\n",
    "    pickle.dump(FILTERED_TITLES, fileobj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a5ebbc-0340-4abd-b243-ad9ffd851017",
   "metadata": {},
   "source": [
    "### Stemmed Titles Headlines\n",
    "\n",
    "Reducing headlines to their basic forms, known as stemming, simplifies the text by converting to their fundamental roots (for instance, changing \"running\" to \"run\"). This process minimizes word variations, making it easier for the model to identify patterns and enhancing classification accuracy. Additionally, it accelerates processing by decreasing the number of unique words that the model needs to understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ccb8dc6b-0f5b-4e2d-a4c0-ee5491ac0676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stemmed Titles Headlines : \n",
      "['closer look water-split solar fuel potenti', 'irresist scent make locust swarm', 'artifici intellig warn ai know us better know', 'glacier could sculpt mar valley studi', 'perseid meteor shower 2020 time see huge bright firebal uk tonight']\n"
     ]
    }
   ],
   "source": [
    "# stemming using porter stemmer\n",
    "\n",
    "# Required Library\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "porter = PorterStemmer()\n",
    "\n",
    "STEMMED_TITLES_HEADLINES = []\n",
    "\n",
    "for title in FILTERED_TITLES:\n",
    "    temp_title = []\n",
    "    for word in title:\n",
    "        temp_title.append(porter.stem(word))\n",
    "\n",
    "    STEMMED_TITLES_HEADLINES.append(\" \".join(temp_title))\n",
    "\n",
    "print(\"\\nStemmed Titles Headlines : \")\n",
    "print(STEMMED_TITLES_HEADLINES[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "9497d013-6a84-4d5b-9a32-4539a198b66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickling STEMMED_TITLES_HEADLINES\n",
    "\n",
    "file = \"pklFiles/STEMMED_TITLES_HEADLINES.pkl\"\n",
    "with open(file, 'wb') as fileobj:\n",
    "    pickle.dump(STEMMED_TITLES_HEADLINES, fileobj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "41c964b9-0794-475d-8820-3fd9c604e7e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>TITLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>closer look water-split solar fuel potenti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>irresist scent make locust swarm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>artifici intellig warn ai know us better know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>glacier could sculpt mar valley studi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>perseid meteor shower 2020 time see huge brigh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CATEGORY                                              TITLE\n",
       "0  SCIENCE         closer look water-split solar fuel potenti\n",
       "1  SCIENCE                   irresist scent make locust swarm\n",
       "2  SCIENCE      artifici intellig warn ai know us better know\n",
       "3  SCIENCE              glacier could sculpt mar valley studi\n",
       "4  SCIENCE  perseid meteor shower 2020 time see huge brigh..."
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Frame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "eda2dc33-a164-4906-946b-d9cf4fdf0d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>TITLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>closer look water-split solar fuel potenti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>irresist scent make locust swarm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>artifici intellig warn ai know us better know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>glacier could sculpt mar valley studi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>perseid meteor shower 2020 time see huge brigh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CATEGORY                                              TITLE\n",
       "0  SCIENCE         closer look water-split solar fuel potenti\n",
       "1  SCIENCE                   irresist scent make locust swarm\n",
       "2  SCIENCE      artifici intellig warn ai know us better know\n",
       "3  SCIENCE              glacier could sculpt mar valley studi\n",
       "4  SCIENCE  perseid meteor shower 2020 time see huge brigh..."
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replacing HEADLINES with STEMMED TITLES HEADLINES\n",
    "df = df.drop(['TITLE'], axis=1)\n",
    "df.insert(1,\"TITLE\",STEMMED_TITLES_HEADLINES, True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8754c46-aade-4bf1-94d0-e2fb5f24d579",
   "metadata": {},
   "source": [
    "### Encoding News Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "0e52dbdc-7675-4214-8b21-466c69e14483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>ENCODED CATEGORY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>closer look water-split solar fuel potenti</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>irresist scent make locust swarm</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>artifici intellig warn ai know us better know</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>glacier could sculpt mar valley studi</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>perseid meteor shower 2020 time see huge brigh...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CATEGORY                                              TITLE  \\\n",
       "0  SCIENCE         closer look water-split solar fuel potenti   \n",
       "1  SCIENCE                   irresist scent make locust swarm   \n",
       "2  SCIENCE      artifici intellig warn ai know us better know   \n",
       "3  SCIENCE              glacier could sculpt mar valley studi   \n",
       "4  SCIENCE  perseid meteor shower 2020 time see huge brigh...   \n",
       "\n",
       "   ENCODED CATEGORY  \n",
       "0                 4  \n",
       "1                 4  \n",
       "2                 4  \n",
       "3                 4  \n",
       "4                 4  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Required Library\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "\n",
    "# Adding Column of ENCODED CATEGORY\n",
    "df.insert(2, \"ENCODED CATEGORY\",labelencoder.fit_transform(df['CATEGORY']),True)\n",
    "\n",
    "# BUSINESS -> 0\n",
    "# ENTERTAINMENT -> 1\n",
    "# HEALTH -> 2\n",
    "# NATION -> 3\n",
    "# SCIENCE -> 4\n",
    "# SPORTS -> 5\n",
    "# TECHNOLOGY -> 6\n",
    "# WORLD -> 7\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "327c9ef1-6ad0-4c63-934f-5b93fc43f59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>ENCODED CATEGORY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>closer look water-split solar fuel potenti</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>irresist scent make locust swarm</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>artifici intellig warn ai know us better know</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>glacier could sculpt mar valley studi</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>perseid meteor shower 2020 time see huge brigh...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CATEGORY                                              TITLE  \\\n",
       "0  SCIENCE         closer look water-split solar fuel potenti   \n",
       "1  SCIENCE                   irresist scent make locust swarm   \n",
       "2  SCIENCE      artifici intellig warn ai know us better know   \n",
       "3  SCIENCE              glacier could sculpt mar valley studi   \n",
       "4  SCIENCE  perseid meteor shower 2020 time see huge brigh...   \n",
       "\n",
       "   ENCODED CATEGORY  \n",
       "0                 4  \n",
       "1                 4  \n",
       "2                 4  \n",
       "3                 4  \n",
       "4                 4  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pickling DataFrame\n",
    "\n",
    "file = \"pklFiles/DATAFRAME.pkl\"\n",
    "with open(file, 'wb') as fileobj:\n",
    "    pickle.dump(df, fileobj)\n",
    "\n",
    "print(type(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6e763f-cbac-49e1-9ecb-3fe276631547",
   "metadata": {},
   "source": [
    "## Using Naive Bayes Classification\n",
    "\n",
    "Naive Bayes classification is an easy-to-use and efficient algorithm that applies probability for data classification. It is based on the assumption that features are independent, which contributes to its speed and often reliable results in applications such as spam detection and text classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa47da9c-0abd-44e4-a378-835371efdb85",
   "metadata": {},
   "source": [
    "### Data Understanding\n",
    "\n",
    "By analyzing the data, We can identify trends, address problems, and make well decisions, which results in outcomes that are both accurate and dependable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "6671b351-0130-4cdc-b780-ab1f4d0988b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>ENCODED CATEGORY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>closer look water-split solar fuel potenti</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>irresist scent make locust swarm</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>artifici intellig warn ai know us better know</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>glacier could sculpt mar valley studi</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>perseid meteor shower 2020 time see huge brigh...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CATEGORY                                              TITLE  \\\n",
       "0  SCIENCE         closer look water-split solar fuel potenti   \n",
       "1  SCIENCE                   irresist scent make locust swarm   \n",
       "2  SCIENCE      artifici intellig warn ai know us better know   \n",
       "3  SCIENCE              glacier could sculpt mar valley studi   \n",
       "4  SCIENCE  perseid meteor shower 2020 time see huge brigh...   \n",
       "\n",
       "   ENCODED CATEGORY  \n",
       "0                 4  \n",
       "1                 4  \n",
       "2                 4  \n",
       "3                 4  \n",
       "4                 4  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading Data Frame\n",
    "import pickle\n",
    "\n",
    "file = \"pklFiles/DATAFRAME.pkl\"\n",
    "fileobj = open(file,'rb')\n",
    "df = pickle.load(fileobj)\n",
    "fileobj.close()\n",
    "\n",
    "print(type(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb16c066-4e56-4df8-a98f-181afaa08ed8",
   "metadata": {},
   "source": [
    "### Selecting features and labels\n",
    "\n",
    "Choosing the right features and labels increases a model's accuracy and efficiency. This focus significant data not only simplifies the model's complexity but also enhances its ability to make correct predictions. Labels present the outcomes that the model must learn from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "dc0b563e-7927-4348-81e3-61f9e328f458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# News Headlines\n",
    "X = df['TITLE']\n",
    "\n",
    "# Encoded News Category\n",
    "Y = df['ENCODED CATEGORY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b4cc4d-45c1-4f2a-8e81-c69638a2c0ea",
   "metadata": {},
   "source": [
    "### data division (test and train)\n",
    "\n",
    "Dividing the dataset into training and testing subsets allows us to evaluate our model's performance on unseen data, helps prevent overfitting, and enables you to adjust it for improved outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ed4e22b3-15c8-48ac-b23f-294592883161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Library\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Testing_set -> 25% and Training_set -> 75%\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.25,random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "6db626ec-46ed-44cc-83ea-76ebde411943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X : (108691,)\n",
      "shape of Y : (108691,)\n",
      "\n",
      "\n",
      "shape of X_train : (81518,)\n",
      "shape of Y_train : (81518,)\n",
      "shape of X_test : (27173,)\n",
      "shape of Y_test : (27173,)\n"
     ]
    }
   ],
   "source": [
    "# understanding how much data is used for training and testing from the original dataset\n",
    "\n",
    "print(\"shape of X : \" + str(X.shape))\n",
    "print(\"shape of Y : \" + str(Y.shape))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"shape of X_train : \" + str(X_train.shape))\n",
    "print(\"shape of Y_train : \" + str(Y_train.shape))\n",
    "print(\"shape of X_test : \" + str(X_test.shape))\n",
    "print(\"shape of Y_test : \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254bcb64-a6de-4756-94b3-517dfafb0934",
   "metadata": {},
   "source": [
    "### Feature Selection \n",
    "\n",
    "Selecting relevant features enhances the accuracy of your model, minimizes the risk offitting, accelerates the process, and simplifies interpretation by concentrating the most crucial data.\n",
    "\n",
    "### Bag of Words (BOW) Approach\n",
    "\n",
    "The Bag of Words (BoW) method converts text into a tally of word occurrences while disregarding grammar and the sequence of words. It formulates a vocabulary containing all distinct words from the dataset, subsequently representing each document as a vector that indicates the frequency of each word. Although it offers a straightforward way to analyze text, it fails to convey the meaning or order of the."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "bd20cffc-569d-46e1-af4f-9e0a0b9ad860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting text documents into matrix of token counts\n",
    "\n",
    "# Required Library\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Intantaition CountVectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "# Fitting & Transforming Training Data (X_train)\n",
    "count_X_train = count_vectorizer.fit_transform(X_train.values)\n",
    "\n",
    "# Transforming Testing Data (x_test)\n",
    "count_X_test = count_vectorizer.transform(X_test.values)\n",
    "\n",
    "# Saving count_vectorizer\n",
    "pickle.dump(count_vectorizer, open(\"pklFiles/count_vectorizer.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6ad4ec-1018-4de7-aa7b-a8c131d40376",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "\n",
    "Model training allows a machine learning model to patterns within data, enabling it to make precise predictions on new information. This process enhances the model's effectiveness and allows it to perform tasks like detecting spam or making product recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "7e817ac4-dd2b-4be3-84a3-a9f27073a35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinomial Naive Classifier -> Predicts category based on the word frequency in text\n",
    "\n",
    "# Required Library\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Instantiating Naive Bayes Classifier with alpha = 1.0\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "# Fitting nb_classifier to training Data \n",
    "nb_classifier.fit(count_X_train, Y_train)\n",
    "\n",
    "# Saving nb_classifier for count_vectorizer\n",
    "pickle.dump(nb_classifier, open(\"pklFiles/nb_classifier_for_count_vectorizer.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d746b67-735b-4029-9b7c-45069a549a38",
   "metadata": {},
   "source": [
    "### Model Prediction\n",
    "\n",
    "Making predictions with a model is crucial for applying its learned insights to new data. This process aids in automating certain tasks, facilitating data-informed decisions, and evaluating the model's performance in real-life scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "f048a3a3-f744-455a-b20d-4ba5a729d60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "pred = nb_classifier.predict(count_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77af92f-e5b7-4e5a-87c0-fe8cbd2dfeda",
   "metadata": {},
   "source": [
    "### Evaluation of Prediction\n",
    "\n",
    "#### Accuracy Score & Confusion Matrix\n",
    "\n",
    "* *Accuracy Score*: Reflects the frequency with which the model produces correct predictions. It is calculated as the proportion of accurate predictions against the overall number of predictions made.\n",
    "* *Confusion Matrix*: A framework that delineates the model's effectiveness by displaying a matrix of true positives, true negatives, false positives, and false negatives. It facilitates the assessment of where the model excels or falters in its predictions, offering deeper insights beyond just the accuracy metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "2da56d53-cb17-4e95-babd-03d43ba4269d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 77.00 %\n",
      "\n",
      "\n",
      "confusion_matrix: \n",
      "[[2744   57  267  174    5   40  215  230]\n",
      " [  42 3234   72  122    8   71  141  110]\n",
      " [ 104   42 3270  142   21   23   32  159]\n",
      " [ 185  143  449 2303   12   84   51  578]\n",
      " [  31   25  104   10  689    3   31   28]\n",
      " [  37  124   56   64    3 3304   59   64]\n",
      " [ 146  148   88   34   26   46 3192   54]\n",
      " [ 185  143  548  488   25   42   60 2186]]\n"
     ]
    }
   ],
   "source": [
    "# Required Library\n",
    "from sklearn import metrics\n",
    "\n",
    "# Accuracy\n",
    "accuracy=metrics.accuracy_score(Y_test,pred)\n",
    "print(\"accuracy: \"+str(\"{:.2f}\".format(accuracy*100)),\"%\")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Confusion Matrix\n",
    "# Labels : 0(BUSINESS), 1(ENTERTAINMENT), 2(HEALTH), 3(NATION), 4(SCIENCE), 5(SPORTS), 6(TECHNOLOGY), 7(WORLD)\n",
    "# By default , Horizontally Labels are from 0 to 3\n",
    "# By default , Vertically Labels are from 0 to 3\n",
    "conf_matrix=metrics.confusion_matrix(Y_test,pred)\n",
    "print(\"confusion_matrix: \")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d49d6f-f7c1-4ea8-a899-76a400487703",
   "metadata": {},
   "source": [
    "##### Laplace Smoothing\n",
    "\n",
    "Laplace smoothing prevents the model from assigning a probability of zero to words or categories that have not been encountered before, ensuring that every potential outcome is considered. This enhancement increases the accuracy and reliability of the model, particularly when it comes to new or infrequent data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "9306d98e-2d31-47d3-8a32-5ded0b022a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha :  0.0\n",
      "Accuracy Score :  0.7130607588414971\n",
      "\n",
      "alpha :  0.1\n",
      "Accuracy Score :  0.7793029845802819\n",
      "\n",
      "alpha :  0.2\n",
      "Accuracy Score :  0.7786037610863725\n",
      "\n",
      "alpha :  0.30000000000000004\n",
      "Accuracy Score :  0.7768005004968167\n",
      "\n",
      "alpha :  0.4\n",
      "Accuracy Score :  0.775549258455084\n",
      "\n",
      "alpha :  0.5\n",
      "Accuracy Score :  0.7750340411437824\n",
      "\n",
      "alpha :  0.6000000000000001\n",
      "Accuracy Score :  0.7742244139403084\n",
      "\n",
      "alpha :  0.7000000000000001\n",
      "Accuracy Score :  0.7725315570603172\n",
      "\n",
      "alpha :  0.8\n",
      "Accuracy Score :  0.7717955323298863\n",
      "\n",
      "alpha :  0.9\n",
      "Accuracy Score :  0.7706914952342399\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/naive_bayes.py:890: RuntimeWarning: divide by zero encountered in log\n",
      "  self.feature_log_prob_ = np.log(smoothed_fc) - np.log(\n"
     ]
    }
   ],
   "source": [
    "# Laplace Smoothing (Tunning paramer - alpha)\n",
    "\n",
    "# List of alphas\n",
    "alphas =np.arange(0,1,0.1)\n",
    "\n",
    "# Function for training nb_classifier with different alpha values\n",
    "def train_and_predict(alpha):\n",
    "    # Instantiating Naive Bayes Classifier\n",
    "    nb_classifier = MultinomialNB(alpha=alpha)\n",
    "\n",
    "    # Fitting nb_classifier to training Data \n",
    "    nb_classifier.fit(count_X_train, Y_train)\n",
    "\n",
    "    # Prediction\n",
    "    pred = nb_classifier.predict(count_X_test)\n",
    "    \n",
    "    # Accuracy Score\n",
    "    accuracy=metrics.accuracy_score(Y_test,pred)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "# Iterating over alphas & printing the corresponding Accuracy Score\n",
    "for alpha in alphas:\n",
    "    print(\"alpha : \",alpha)\n",
    "    print(\"Accuracy Score : \",train_and_predict(alpha))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92413144-5c3a-4fc6-8921-e4091e90235a",
   "metadata": {},
   "source": [
    " with alpha=1.0, we got accuracy of 77%.\n",
    "\n",
    " then, trying different values of alpha, still we are getting approximate accuracy of 77%\n",
    "\n",
    " so, we don't need to change the value of alpha."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ef9fee-9990-434a-8c25-792bce9ea0bd",
   "metadata": {},
   "source": [
    "### Loading Model\n",
    "\n",
    "* *Count Vectorizer*: This tool converts text into numerical values by tallying the frequency of each word found in a document. It transforms text into a format that algorithms can utilize.\n",
    "* *Naive Bayes Classifier*: This algorithm applies these numerical values to make predictions about categories. For instance, it can determine whether an email is spam on its word composition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "ca80dd02-0633-446e-b419-a2d3f0570148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "try:\n",
    "    # Load the CountVectorizer and Naive Bayes Classifier\n",
    "    with open(\"pklFiles/count_vectorizer.pkl\", \"rb\") as f:\n",
    "        count_vectorizer = pickle.load(f)\n",
    "\n",
    "    with open(\"pklFiles/nb_classifier_for_count_vectorizer.pkl\", \"rb\") as f:\n",
    "        nb_classifier = pickle.load(f)\n",
    "\n",
    "    print(\"Models loaded successfully.\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"File not found: {e}\")\n",
    "\n",
    "except pickle.UnpicklingError as e:\n",
    "    print(f\"Error unpickling object: {e}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065e40c5-0ffd-4a45-ba02-216aea95887a",
   "metadata": {},
   "source": [
    "### Taking User Input\n",
    "\n",
    "User input helps machine learning models give more accurate and personalized results. It allows the model to adapt to what each individual needs or prefers, making its predictions or recommendations more relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "bc0fd94b-e80b-42c3-b2f7-00c89f41a7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "News Headline :  https://timesofindia.indiatimes.com/world/south-asia/bangladesh-currency-drops-bangabandhus-image-new-notes-without-sheikh-mujibur-rahmans-picture-are-out/articleshow/121559121.cms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "News Category :  WORLD\n"
     ]
    }
   ],
   "source": [
    "# Value encoded by Label Encoder\n",
    "encoded = {0:'BUSINESS',1:'ENTERTAINMENT',2:'HEALTH',3:'NATION',4:'SCIENCE',5:'SPORTS',6:'TECHNOLOGY',7:'WORLD'}\n",
    "\n",
    "# Input\n",
    "User_Headline = [input(\"News Headline : \")]\n",
    "\n",
    "# Transformation and Prediction of User Headline\n",
    "Headline_counts = count_vectorizer.transform(User_Headline)\n",
    "prediction = nb_classifier.predict(Headline_counts)\n",
    "\n",
    "print(\"News Category : \",encoded[prediction[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f0f663-e7b3-496c-800c-353b59f75bfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
